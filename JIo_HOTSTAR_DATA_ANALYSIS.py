# -*- coding: utf-8 -*-
"""hotstar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17tagS-tUfuPrWsGwPumflzV8w6HKA_Po
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt# Seaborn is built on Matplotlib and provides a high-level interface
# for drawing attractive and informative statistical graphics.
plt.style.use('ggplot')
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score, classification_report, roc_curve, auc
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
# Ensemble Model
from sklearn.ensemble import RandomForestClassifier

df=pd.read_csv("hotstar.csv")
df

df.head()

df.tail()

df.info()

df.describe()

# --- Handling Structural Missing Data for 'seasons' and 'episodes' ---
# Fill NaN for 'seasons' and 'episodes' with 0, as this typically indicates a movie.
df['seasons'] = df['seasons'].fillna(0)
df['episodes'] = df['episodes'].fillna(0)

# --- Handling Missing 'running_time' (for TV shows) ---
# Impute missing 'running_time' with the median of the existing data (mostly movies).
median_runtime = df['running_time'].median()
df['running_time'] = df['running_time'].fillna(median_runtime)

# --- Check for Duplicates ---
print("\n--- Duplicates Check ---")
duplicate_count = df.duplicated().sum()
print(f"Number of duplicate rows found: {duplicate_count}")

if duplicate_count > 0:
    # Remove duplicate rows and update the DataFrame in place
    df.drop_duplicates(inplace=True)
    print(f"Duplicates removed. New row count: {len(df)}")
else:
    print("No duplicates found to remove.")

# --- Verify Cleanup ---
print("\n--- Post-Cleaning Info Check ---")
print(df.info())

#EDA
sns.countplot(x='type', data=df)
plt.title('Content Type Distribution')
plt.xlabel('Type')
plt.ylabel('Count')
plt.show()

sns.histplot(df['year'])
plt.title('Content Production Year Distribution')
plt.xlabel('Year')
plt.ylabel('Count')
plt.show()

sns.countplot(x='age_rating', hue='type', data=df)
plt.title('Content Type by Age Rating')
plt.xlabel('Age Rating')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(9, 6))
sns.boxplot(x='type', y='running_time', data=df)
plt.title('Running Time by Content Type')
plt.xlabel('Content Type')
plt.ylabel('Running Time (minutes)')
plt.show()

numerical_df = df[['year', 'running_time', 'seasons', 'episodes']]

sns.heatmap(numerical_df.corr(), annot=True)
plt.title('Correlation Between Numerical Features')
plt.show()

plt.figure(figsize=(12, 6))
genre_counts = df['genre'].apply(lambda x: x.split(',')[0]).value_counts().head(10)

sns.barplot(x=genre_counts.index, y=genre_counts.values)
plt.title('Top 10 Primary Genres')
plt.xlabel('Genre')
plt.ylabel('Count')
plt.show()

tv_df = df[(df['type'] == 'tv') & (df['seasons'] > 0)]

sns.scatterplot(x='seasons', y='episodes', data=tv_df)
plt.title('Seasons vs Episodes for TV Shows')
plt.xlabel('Number of Seasons')
plt.ylabel('Number of Episodes')
plt.show()

# 1Ô∏è‚É£ Take only the first genre (like "Action, Drama" ‚Üí "Action")
df['primary_genre'] = df['genre'].apply(lambda x: x.split(',')[0])

# 2Ô∏è‚É£ Keep only the columns we need
df_model = df[['year', 'running_time', 'seasons', 'episodes', 'primary_genre', 'age_rating', 'type']]

# 3Ô∏è‚É£ Convert text columns into numbers (1s and 0s)
df_encoded = pd.get_dummies(df_model, columns=['primary_genre', 'age_rating', 'type'])

# 4Ô∏è‚É£ Split data into features (X) and target (y)
X = df_encoded.drop('type_tv', axis=1)
y = df_encoded['type_tv']

# 5Ô∏è‚É£ Show the result
print("‚úÖ Data ready for model training!")
print("Target column: type_tv (1 = TV Show, 0 = Movie)")
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)
print("\nSample data:\n", X.head())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("‚úÖ Data Split Done!")
print("Training samples:", X_train.shape[0])
print("Testing samples:", X_test.shape[0])
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=1000, random_state=42)  # Simple classification model

model.fit(X_train, y_train)   # Learn patterns from the training data
y_pred = model.predict(X_test)  # Predict on unseen data
from sklearn.metrics import classification_report
print("\nüìä Model Performance:")
print(classification_report(y_test, y_pred, target_names=['Movie (0)', 'TV Show (1)']))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression(max_iter=1000, random_state=42)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
lr_scores = cross_val_score(lr_model, X, y, cv=5, scoring='accuracy')
print(f"Logistic Regression Avg. Accuracy: {lr_scores.mean():.4f} (Std: {lr_scores.std():.4f})")

from sklearn.metrics import roc_curve, auc, classification_report
import matplotlib.pyplot as plt

# --- A. Train the Superior Model (Random Forest) ---
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
y_proba_rf = rf_model.predict_proba(X_test)[:, 1] # Get probabilities for the positive class (TV Show)

print("\n--- Final Random Forest Classification Report (on Test Set) ---")
print(classification_report(y_test, y_pred_rf, target_names=['Movie (0)', 'TV Show (1)']))


# --- B. Calculate and Plot AUC Score ---
fpr, tpr, thresholds = roc_curve(y_test, y_proba_rf)
roc_auc = auc(fpr, tpr)
print(f"\nArea Under the Curve (AUC) Score: {roc_auc:.4f}")

plt.figure(figsize=(18, 18))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Recall)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()


# --- C. Feature Importance (Interpretability) ---
print("\n--- Feature Importance for Random Forest ---")
# Extract importance from the trained model
importance = pd.Series(rf_model.feature_importances_, index=X_train.columns)
# Plot the top 10 most important features
importance.nlargest(10).sort_values().plot(kind='barh', figsize=(10, 6), color='teal')
plt.title('Top 10 Feature Importances')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

# Print the top 3 features for summary
print("\nTop 3 Driving Features:")
print(importance.nlargest(3))